{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2aa3c1a",
   "metadata": {},
   "source": [
    "# Car System Agentic AI - Template\n",
    "\n",
    "**Project:** Agentic AI example  \n",
    "**Author:** Klaus  \n",
    "**License:** MIT License\n",
    "\n",
    "---\n",
    "\n",
    "This notebook demonstrates the car diagnostic system using LangGraph with multiple specialized nodes for input validation, reasoning, and output processing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfdbcfd",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfcfd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m[\u001b[90m2025-09-23 12:34:30\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34m__init__.py:46\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔑 Environment loaded from: /home/klaus/Projects/car-system-agentic-ai/.env\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:30\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34m__init__.py:48\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔑 GOOGLE_API_KEY: ✅ Found\n"
     ]
    }
   ],
   "source": [
    "exec(open('setup.py').read())\n",
    "\n",
    "from notebooks import *\n",
    "from langgraph.constants import START\n",
    "from langgraph.graph import StateGraph\n",
    "from src.data_models.graph_state import CarSystemState\n",
    "from src.tools.car import get_car_status\n",
    "from src.tools.calculations import is_trip_possible\n",
    "from src.tools.travel import recommend_locations\n",
    "from src.tools.weather import get_predicted_weather\n",
    "from src.tools.agent_registry import list_registered_agents, invoke_agent\n",
    "from src.utils.prompt_loader import get_prompt\n",
    "from src.utils.agent_card_loader import load_agent_cards_from_file\n",
    "from src.services.agent_registry import AgentRegistry\n",
    "from src.utils.test_graph import test_graph\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c6571c",
   "metadata": {},
   "source": [
    "# Load Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f77d6517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m[\u001b[90m2025-09-23 12:34:30\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95mprompt_loader.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔍 PromptLoader: Loaded prompt output_guard_rail\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:30\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95mprompt_loader.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔍 PromptLoader: Loaded prompt input_guard_rail\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:30\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95mprompt_loader.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔍 PromptLoader: Loaded prompt reasoning_node\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:30\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95mprompt_loader.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔍 PromptLoader: Loaded prompt car_central\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:30\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95mprompt_loader.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔍 PromptLoader: Loaded prompt trip_planner\n"
     ]
    }
   ],
   "source": [
    "# Load all prompts\n",
    "output_guard_rail_prompt = get_prompt(\"output_guard_rail\")\n",
    "input_guard_rail_prompt = get_prompt(\"input_guard_rail\") \n",
    "reasoning_node_prompt = get_prompt(\"reasoning_node\")\n",
    "car_central_prompt = get_prompt(\"car_central\")\n",
    "trip_planner_prompt = get_prompt(\"trip_planner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfe5735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and register AgentCards from JSON (pt-BR)\n",
    "cards_path = Path.cwd().parent / \"data\" / \"agent_cards.json\"\n",
    "agent_cards = load_agent_cards_from_file(cards_path)\n",
    "AgentRegistry.clear()\n",
    "\n",
    "# Extract specific cards by name\n",
    "car_card = next(c for c in agent_cards if c.name == \"AgenteDiagnosticoCarro\")\n",
    "trip_card = next(c for c in agent_cards if c.name == \"AgentePlanejadorViagem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5940d3a4",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d4d94d",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d489588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m[\u001b[90m2025-09-23 12:34:30\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:57\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔗 Gemini: tools bound -> ['get_car_status']\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:30\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:63\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🤖 GeminiModel: Initialized with model gemini-2.5-flash [agent=AgenteDiagnosticoCarro]\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:30\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:57\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔗 Gemini: tools bound -> ['recommend_locations', 'get_predicted_weather']\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:30\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:63\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🤖 GeminiModel: Initialized with model gemini-2.5-flash [agent=AgentePlanejadorViagem]\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:30\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:68\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🤖 GeminiModel: Initialized with model gemini-2.5-flash\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:30\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:57\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔗 Gemini: tools bound -> ['list_registered_agents', 'invoke_agent', 'is_trip_possible']\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:30\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:68\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🤖 GeminiModel: Initialized with model gemini-2.5-flash\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:30\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:68\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🤖 GeminiModel: Initialized with model gemini-2.5-flash\n"
     ]
    }
   ],
   "source": [
    "# Specialized agents\n",
    "\n",
    "car_agent_model = models.GeminiModel(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    prompt=car_central_prompt,\n",
    "    agent_card=car_card,\n",
    "    tools=[get_car_status],\n",
    ")\n",
    "\n",
    "trip_planner_agent_model = models.GeminiModel(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    prompt=trip_planner_prompt,\n",
    "    agent_card=trip_card,\n",
    "    tools=[recommend_locations, get_predicted_weather],\n",
    ")\n",
    "\n",
    "# Register cards with their models\n",
    "AgentRegistry.register(car_card, car_agent_model)\n",
    "AgentRegistry.register(trip_card, trip_planner_agent_model)\n",
    "\n",
    "# Graph agents\n",
    "\n",
    "# Input guard rail agent\n",
    "input_guard_rail_agent = models.GeminiModel(\n",
    "    model=\"gemini-2.5-flash\", \n",
    "    prompt=input_guard_rail_prompt\n",
    ")\n",
    "\n",
    "# Reasoning agent (orchestration + quick feasibility)\n",
    "reasoning_agent = models.GeminiModel(\n",
    "    model=\"gemini-2.5-flash\", \n",
    "    prompt=reasoning_node_prompt,\n",
    "    tools=[list_registered_agents, invoke_agent, is_trip_possible],\n",
    ")\n",
    "\n",
    "# Output guard rail agent\n",
    "output_guard_rail_agent = models.GeminiModel(\n",
    "    model=\"gemini-2.5-flash\", \n",
    "    prompt=output_guard_rail_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e64c756",
   "metadata": {},
   "source": [
    "## Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e301d75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m[\u001b[90m2025-09-23 12:34:30\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;91minput_guard_rail.py:36\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | InputGuardRail: Initialized\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:30\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;35m_node_with_tools.py:50\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | NodeWithTools: Initialized\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:30\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95moutput_guard_rail.py:41\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | OutputGuardRail: Initialized\n"
     ]
    }
   ],
   "source": [
    "# node definition\n",
    "ENTRYPOINT = START\n",
    "INPUT_GUARD_RAIL = \"input_guard_rail\"\n",
    "REASONING_NODE = \"reasoning_node\"\n",
    "OUTPUT_GUARD_RAIL = \"output_guard_rail\"\n",
    "EXIT_ZONE = \"end\"\n",
    "\n",
    "input_guard_rail = nodes.InputGuardRail(\n",
    "    routing_options={\"next_node\": REASONING_NODE, \"end\": OUTPUT_GUARD_RAIL},\n",
    "    model=input_guard_rail_agent,\n",
    ")\n",
    "\n",
    "reasoning_node = nodes.ReasoningNode(\n",
    "    routing_options={\"next_node\": OUTPUT_GUARD_RAIL, \"end\": OUTPUT_GUARD_RAIL},\n",
    "    model=reasoning_agent,\n",
    ")\n",
    "\n",
    "output_guard_rail = nodes.OutputGuardRail(\n",
    "    routing_options={\"end\": EXIT_ZONE},\n",
    "    model=output_guard_rail_agent,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12174ec2",
   "metadata": {},
   "source": [
    "## Graph Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "213ceb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph with state_schema parameter\n",
    "workflow = StateGraph(state_schema=CarSystemState)\n",
    "\n",
    "# Add nodes to the graph\n",
    "workflow.add_node(INPUT_GUARD_RAIL, input_guard_rail)\n",
    "workflow.add_node(REASONING_NODE, reasoning_node)\n",
    "workflow.add_node(OUTPUT_GUARD_RAIL, output_guard_rail)\n",
    "\n",
    "# Define the flow with conditional routing\n",
    "# Os nodes usam Command para determinar o próximo node baseado no estado\n",
    "workflow.add_edge(START, \"input_guard_rail\")\n",
    "#workflow.add_edge(EXIT_ZONE, lambda state: Command(goto=END))\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513fd2ac",
   "metadata": {},
   "source": [
    "# Test Graph Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "326c616c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Testing graph execution (synchronous)...\n",
      "Input message: Qual local voce recomenda para eu viajar?\n",
      "------------------------------------------------------------\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:30\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;91minput_guard_rail.py:44\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🛡️ InputGuardRail: Starting execution\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:30\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;91minput_guard_rail.py:59\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 📨 Processing message: Qual local voce recomenda para eu viajar?...\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:32\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:102\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 386, 'output_tokens': 57, 'total_tokens': 443, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 40}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:32\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;91minput_guard_rail.py:71\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | ✅ Validation result: is_valid=True\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:32\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;91minput_guard_rail.py:77\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🚀 Routing to next_node: reasoning_node\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:32\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93mreasoning_node.py:28\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧠 ReasoningNode: Starting execution\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:32\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93mreasoning_node.py:48\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 📨 Processing message: Qual local voce recomenda para eu viajar?...\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:34\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 959, 'output_tokens': 98, 'total_tokens': 1057, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 86}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:34\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95m_chat_model.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧰 invoke_with_tools: tool_calls=['list_registered_agents']\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:34\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34magent_registry.py:27\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🗂️ list_registered_agents: 2 agentes\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:35\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 1043, 'output_tokens': 167, 'total_tokens': 1210, 'input_token_details': {'cache_read': 726}, 'output_token_details': {'reasoning': 104}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:35\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95m_chat_model.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧰 invoke_with_tools: tool_calls=['invoke_agent']\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:35\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34magent_registry.py:36\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔁 invoke_agent: agent='AgenteDiagnosticoCarro', query[:120]='Qual o status do meu carro, nível de combustível e autonomia?'\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:35\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;35magent_registry.py:98\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧩 AgentRegistry.invoke: agent='AgenteDiagnosticoCarro', query[:120]='Qual o status do meu carro, nível de combustível e autonomia?'\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:37\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 342, 'output_tokens': 67, 'total_tokens': 409, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 55}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:37\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95m_chat_model.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧰 invoke_with_tools: tool_calls=['get_car_status']\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:37\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93mcar.py:24\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔧 Getting car status: gas_liters=53, current_autonomy=9\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:39\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 391, 'output_tokens': 100, 'total_tokens': 491, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 78}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:39\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;35magent_registry.py:127\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧩 AgentRegistry.invoke: resposta len=77\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:39\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34magent_registry.py:41\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔁 invoke_agent: resposta len=77\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:40\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 1119, 'output_tokens': 36, 'total_tokens': 1155, 'input_token_details': {'cache_read': 734}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:40\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95m_chat_model.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧰 invoke_with_tools: tool_calls=['invoke_agent']\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:40\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34magent_registry.py:36\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔁 invoke_agent: agent='AgentePlanejadorViagem', query[:120]='Quais locais você recomenda para eu viajar?'\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:40\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;35magent_registry.py:98\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧩 AgentRegistry.invoke: agent='AgentePlanejadorViagem', query[:120]='Quais locais você recomenda para eu viajar?'\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:42\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 776, 'output_tokens': 137, 'total_tokens': 913, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 119}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:42\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95m_chat_model.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧰 invoke_with_tools: tool_calls=['recommend_locations']\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:42\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93mtravel.py:33\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🌍 recommend_locations: query='destinos variados'\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:42\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93mtravel.py:106\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🌍 recommend_locations: retornando 3 destinos\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:44\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 1026, 'output_tokens': 121, 'total_tokens': 1147, 'input_token_details': {'cache_read': 722}, 'output_token_details': {'reasoning': 102}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:44\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95m_chat_model.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧰 invoke_with_tools: tool_calls=['get_predicted_weather']\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:44\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;91mweather.py:39\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🌤️ Getting weather for Florianópolis: parcialmente nublado\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:44\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 1073, 'output_tokens': 21, 'total_tokens': 1094, 'input_token_details': {'cache_read': 726}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:44\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95m_chat_model.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧰 invoke_with_tools: tool_calls=['get_predicted_weather']\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:44\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;91mweather.py:39\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🌤️ Getting weather for Campos do Jordão: nublado\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:45\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 1123, 'output_tokens': 19, 'total_tokens': 1142, 'input_token_details': {'cache_read': 730}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:45\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95m_chat_model.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧰 invoke_with_tools: tool_calls=['get_predicted_weather']\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:45\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;91mweather.py:39\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🌤️ Getting weather for Ouro Preto: chuvoso\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:52\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 1171, 'output_tokens': 816, 'total_tokens': 1987, 'input_token_details': {'cache_read': 733}, 'output_token_details': {'reasoning': 595}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:52\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;35magent_registry.py:127\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧩 AgentRegistry.invoke: resposta len=816\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:52\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34magent_registry.py:41\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔁 invoke_agent: resposta len=816\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:55\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 1404, 'output_tokens': 315, 'total_tokens': 1719, 'input_token_details': {'cache_read': 774}, 'output_token_details': {'reasoning': 284}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:55\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95m_chat_model.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧰 invoke_with_tools: tool_calls=['is_trip_possible']\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:55\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;35mcalculations.py:20\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔧 Checking if trip is possible: distance=300.0, autonomy=9.0, gas=53.0\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:34:55\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;35mcalculations.py:27\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔧 Trip feasibility: needed_gas=33.3333, available_gas=53.0000, possible=True\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:01\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 1452, 'output_tokens': 588, 'total_tokens': 2040, 'input_token_details': {'cache_read': 776}, 'output_token_details': {'reasoning': 404}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:01\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93mreasoning_node.py:71\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🚀 Routing to next_node: output_guard_rail\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:01\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95moutput_guard_rail.py:56\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🛡️ OutputGuardRail: Starting execution\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:01\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95moutput_guard_rail.py:68\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | ✅ Processing successful analysis\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:01\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95moutput_guard_rail.py:161\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔍 Validating recommendations for safety\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:13\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 1076, 'output_tokens': 1473, 'total_tokens': 2549, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1076}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:13\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95moutput_guard_rail.py:204\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | ✅ Recommendations processed and validated\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:13\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95moutput_guard_rail.py:205\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 📤 Final message length: 1537 chars\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:13\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94m_algo.py:287\u001b[37m)\u001b[0m \u001b[33mWARNING\u001b[0m | Task output_guard_rail with path ('__pregel_pull', 'output_guard_rail') wrote to unknown channel branch:to:end, ignoring it.\n",
      "------------------------------------------------------------\n",
      "✅ Synchronous graph execution successful!\n",
      "\n",
      "📊 Final State:\n",
      "------------------------------\n",
      "Pergunta original:  Qual local voce recomenda para eu viajar?\n",
      "Resposta:  Com base nas informações do seu carro (53 litros de combustível e autonomia de 9 km/litro), posso recomendar os seguintes destinos:\n",
      "\n",
      "*   **Florianópolis**: A viagem de 300 km é **possível** com o seu nível atual de combustível. O clima está parcialmente nublado, ideal para aproveitar as praias e a cultura açoriana.\n",
      "*   **Campos do Jordão**: A viagem de 180 km é **possível** com o seu nível atual de combustível. O clima está nublado, perfeito para desfrutar da cidade serrana com clima europeu.\n",
      "*   **Ouro Preto**: A viagem de 450 km **não é possível** com o seu nível atual de combustível. Você precisaria reabastecer para chegar a esta cidade histórica. Além disso, a previsão é de tempo chuvoso.\n"
     ]
    }
   ],
   "source": [
    "human_query = \"Qual local voce recomenda para eu viajar?\"\n",
    "sync_result = test_graph(app, human_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6381c892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Testing graph execution (synchronous)...\n",
      "Input message: Quero viajar 300 km amanhã. Com o combustível que tenho dá para ir sem reabastecer?\n",
      "------------------------------------------------------------\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:13\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;91minput_guard_rail.py:44\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🛡️ InputGuardRail: Starting execution\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:13\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;91minput_guard_rail.py:59\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 📨 Processing message: Quero viajar 300 km amanhã. Com o combustível que tenho dá para ir sem reabastecer?...\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:14\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:102\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 404, 'output_tokens': 98, 'total_tokens': 502, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 81}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:14\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;91minput_guard_rail.py:71\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | ✅ Validation result: is_valid=True\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:14\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;91minput_guard_rail.py:77\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🚀 Routing to next_node: reasoning_node\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:14\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93mreasoning_node.py:28\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧠 ReasoningNode: Starting execution\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:14\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93mreasoning_node.py:48\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 📨 Processing message: Quero viajar 300 km amanhã. Com o combustível que tenho dá para ir sem reabastecer?...\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:16\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 977, 'output_tokens': 196, 'total_tokens': 1173, 'input_token_details': {'cache_read': 718}, 'output_token_details': {'reasoning': 184}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:16\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95m_chat_model.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧰 invoke_with_tools: tool_calls=['list_registered_agents']\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:16\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34magent_registry.py:27\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🗂️ list_registered_agents: 2 agentes\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:17\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 1061, 'output_tokens': 38, 'total_tokens': 1099, 'input_token_details': {'cache_read': 729}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:17\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95m_chat_model.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧰 invoke_with_tools: tool_calls=['invoke_agent']\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:17\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34magent_registry.py:36\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔁 invoke_agent: agent='AgenteDiagnosticoCarro', query[:120]='Qual o status do combustível e autonomia do meu carro?'\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:17\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;35magent_registry.py:98\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧩 AgentRegistry.invoke: agent='AgenteDiagnosticoCarro', query[:120]='Qual o status do combustível e autonomia do meu carro?'\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:18\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 340, 'output_tokens': 64, 'total_tokens': 404, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 52}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:18\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95m_chat_model.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧰 invoke_with_tools: tool_calls=['get_car_status']\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:18\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93mcar.py:24\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔧 Getting car status: gas_liters=37, current_autonomy=11\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:20\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 390, 'output_tokens': 109, 'total_tokens': 499, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 86}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:20\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;35magent_registry.py:127\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧩 AgentRegistry.invoke: resposta len=76\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:20\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34magent_registry.py:41\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔁 invoke_agent: resposta len=76\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:22\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 1136, 'output_tokens': 166, 'total_tokens': 1302, 'input_token_details': {'cache_read': 738}, 'output_token_details': {'reasoning': 101}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:22\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95m_chat_model.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧰 invoke_with_tools: tool_calls=['is_trip_possible']\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:22\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;35mcalculations.py:20\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔧 Checking if trip is possible: distance=300.0, autonomy=11.0, gas=37.0\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:22\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;35mcalculations.py:27\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔧 Trip feasibility: needed_gas=27.2727, available_gas=37.0000, possible=True\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:23\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 1185, 'output_tokens': 35, 'total_tokens': 1220, 'input_token_details': {'cache_read': 741}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:23\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93mreasoning_node.py:71\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🚀 Routing to next_node: output_guard_rail\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:23\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95moutput_guard_rail.py:56\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🛡️ OutputGuardRail: Starting execution\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:23\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95moutput_guard_rail.py:68\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | ✅ Processing successful analysis\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:23\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95moutput_guard_rail.py:161\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔍 Validating recommendations for safety\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:30\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 778, 'output_tokens': 521, 'total_tokens': 1299, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 416}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:30\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95moutput_guard_rail.py:204\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | ✅ Recommendations processed and validated\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:30\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95moutput_guard_rail.py:205\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 📤 Final message length: 412 chars\n",
      "\u001b[37m[\u001b[90m2025-09-23 12:35:30\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94m_algo.py:287\u001b[37m)\u001b[0m \u001b[33mWARNING\u001b[0m | Task output_guard_rail with path ('__pregel_pull', 'output_guard_rail') wrote to unknown channel branch:to:end, ignoring it.\n",
      "------------------------------------------------------------\n",
      "✅ Synchronous graph execution successful!\n",
      "\n",
      "📊 Final State:\n",
      "------------------------------\n",
      "Pergunta original:  Quero viajar 300 km amanhã. Com o combustível que tenho dá para ir sem reabastecer?\n",
      "Resposta:  Sim, com 37 litros de combustível e uma autonomia de 11 km/litro, você consegue viajar 300 km sem reabastecer.\n"
     ]
    }
   ],
   "source": [
    "human_query = \"Quero viajar 300 km amanhã. Com o combustível que tenho dá para ir sem reabastecer?\"\n",
    "sync_result = test_graph(app, human_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
