{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2aa3c1a",
   "metadata": {},
   "source": [
    "# Car System Agentic AI - Template\n",
    "\n",
    "**Project:** Agentic AI example  \n",
    "**Author:** Klaus  \n",
    "**License:** MIT License\n",
    "\n",
    "---\n",
    "\n",
    "This notebook demonstrates the car diagnostic system using LangGraph with multiple specialized nodes for input validation, reasoning, and output processing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfdbcfd",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cfcfd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m[\u001b[90m2025-09-23 17:07:08\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34m__init__.py:46\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔑 Environment loaded from: /home/klaus/Projects/car-system-agentic-ai/.env\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:08\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34m__init__.py:48\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔑 GOOGLE_API_KEY: ✅ Found\n"
     ]
    }
   ],
   "source": [
    "exec(open('setup.py').read())\n",
    "\n",
    "from notebooks import *\n",
    "from langgraph.constants import START\n",
    "from langgraph.graph import StateGraph\n",
    "from src.data_models.graph_state import CarSystemState\n",
    "from src.tools.car import get_car_status\n",
    "from src.tools.calculations import is_trip_possible\n",
    "from src.tools.travel import recommend_locations\n",
    "from src.tools.weather import get_predicted_weather\n",
    "from src.tools.agent_registry import list_registered_agents, invoke_agent\n",
    "from src.utils.prompt_loader import get_prompt\n",
    "from src.utils.agent_card_loader import load_agent_cards_from_file\n",
    "from src.services.agent_registry import AgentRegistry\n",
    "from src.utils.test_graph import test_graph\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c6571c",
   "metadata": {},
   "source": [
    "# Load Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f77d6517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m[\u001b[90m2025-09-23 17:07:08\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;35mprompt_loader.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔍 PromptLoader: Loaded prompt output_guard_rail\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:08\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;35mprompt_loader.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔍 PromptLoader: Loaded prompt input_guard_rail\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:08\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;35mprompt_loader.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔍 PromptLoader: Loaded prompt reasoning_node\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:08\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;35mprompt_loader.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔍 PromptLoader: Loaded prompt car_central\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:08\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;35mprompt_loader.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔍 PromptLoader: Loaded prompt trip_planner\n"
     ]
    }
   ],
   "source": [
    "# Load all prompts\n",
    "output_guard_rail_prompt = get_prompt(\"output_guard_rail\")\n",
    "input_guard_rail_prompt = get_prompt(\"input_guard_rail\") \n",
    "reasoning_node_prompt = get_prompt(\"reasoning_node\")\n",
    "car_central_prompt = get_prompt(\"car_central\")\n",
    "trip_planner_prompt = get_prompt(\"trip_planner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfe5735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and register AgentCards from JSON (pt-BR)\n",
    "cards_path = Path.cwd().parent / \"data\" / \"agent_cards.json\"\n",
    "agent_cards = load_agent_cards_from_file(cards_path)\n",
    "AgentRegistry.clear()\n",
    "\n",
    "# Extract specific cards by name\n",
    "car_card = next(c for c in agent_cards if c.name == \"AgenteDiagnosticoCarro\")\n",
    "trip_card = next(c for c in agent_cards if c.name == \"AgentePlanejadorViagem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5940d3a4",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d4d94d",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d489588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m[\u001b[90m2025-09-23 17:07:08\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:57\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔗 Gemini: tools bound -> ['get_car_status']\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:08\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:63\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🤖 GeminiModel: Initialized with model gemini-2.5-flash [agent=AgenteDiagnosticoCarro]\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:08\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:57\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔗 Gemini: tools bound -> ['recommend_locations', 'get_predicted_weather']\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:08\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:63\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🤖 GeminiModel: Initialized with model gemini-2.5-flash [agent=AgentePlanejadorViagem]\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:08\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:68\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🤖 GeminiModel: Initialized with model gemini-2.5-flash\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m[\u001b[90m2025-09-23 17:07:08\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:57\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔗 Gemini: tools bound -> ['list_registered_agents', 'invoke_agent', 'is_trip_possible']\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:08\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:68\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🤖 GeminiModel: Initialized with model gemini-2.5-flash\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:08\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:68\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🤖 GeminiModel: Initialized with model gemini-2.5-flash\n"
     ]
    }
   ],
   "source": [
    "# Specialized agents\n",
    "\n",
    "car_agent_model = models.GeminiModel(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    prompt=car_central_prompt,\n",
    "    agent_card=car_card,\n",
    "    tools=[get_car_status],\n",
    ")\n",
    "\n",
    "trip_planner_agent_model = models.GeminiModel(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    prompt=trip_planner_prompt,\n",
    "    agent_card=trip_card,\n",
    "    tools=[recommend_locations, get_predicted_weather],\n",
    ")\n",
    "\n",
    "# Register cards with their models\n",
    "AgentRegistry.register(car_card, car_agent_model)\n",
    "AgentRegistry.register(trip_card, trip_planner_agent_model)\n",
    "\n",
    "# Graph agents\n",
    "\n",
    "# Input guard rail agent\n",
    "input_guard_rail_agent = models.GeminiModel(\n",
    "    model=\"gemini-2.5-flash\", \n",
    "    prompt=input_guard_rail_prompt\n",
    ")\n",
    "\n",
    "# Reasoning agent (orchestration + quick feasibility)\n",
    "reasoning_agent = models.GeminiModel(\n",
    "    model=\"gemini-2.5-flash\", \n",
    "    prompt=reasoning_node_prompt,\n",
    "    tools=[list_registered_agents, invoke_agent, is_trip_possible],\n",
    ")\n",
    "\n",
    "# Output guard rail agent\n",
    "output_guard_rail_agent = models.GeminiModel(\n",
    "    model=\"gemini-2.5-flash\", \n",
    "    prompt=output_guard_rail_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e64c756",
   "metadata": {},
   "source": [
    "## Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e301d75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m[\u001b[90m2025-09-23 17:07:08\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93minput_guard_rail.py:36\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | InputGuardRail: Initialized\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:08\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93m_node_with_tools.py:50\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | NodeWithTools: Initialized\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:08\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93moutput_guard_rail.py:41\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | OutputGuardRail: Initialized\n"
     ]
    }
   ],
   "source": [
    "# node definition\n",
    "ENTRYPOINT = START\n",
    "INPUT_GUARD_RAIL = \"input_guard_rail\"\n",
    "REASONING_NODE = \"reasoning_node\"\n",
    "OUTPUT_GUARD_RAIL = \"output_guard_rail\"\n",
    "EXIT_ZONE = \"end\"\n",
    "\n",
    "input_guard_rail = nodes.InputGuardRail(\n",
    "    routing_options={\"next_node\": REASONING_NODE, \"end\": OUTPUT_GUARD_RAIL},\n",
    "    model=input_guard_rail_agent,\n",
    ")\n",
    "\n",
    "reasoning_node = nodes.ReasoningNode(\n",
    "    routing_options={\"next_node\": OUTPUT_GUARD_RAIL, \"end\": OUTPUT_GUARD_RAIL},\n",
    "    model=reasoning_agent,\n",
    ")\n",
    "\n",
    "output_guard_rail = nodes.OutputGuardRail(\n",
    "    routing_options={\"end\": EXIT_ZONE},\n",
    "    model=output_guard_rail_agent,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12174ec2",
   "metadata": {},
   "source": [
    "## Graph Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "213ceb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph with state_schema parameter\n",
    "workflow = StateGraph(state_schema=CarSystemState)\n",
    "\n",
    "# Add nodes to the graph\n",
    "workflow.add_node(INPUT_GUARD_RAIL, input_guard_rail)\n",
    "workflow.add_node(REASONING_NODE, reasoning_node)\n",
    "workflow.add_node(OUTPUT_GUARD_RAIL, output_guard_rail)\n",
    "\n",
    "# Define the flow with conditional routing\n",
    "# Os nodes usam Command para determinar o próximo node baseado no estado\n",
    "workflow.add_edge(START, \"input_guard_rail\")\n",
    "#workflow.add_edge(EXIT_ZONE, lambda state: Command(goto=END))\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513fd2ac",
   "metadata": {},
   "source": [
    "# Test Graph Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "326c616c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Testing graph execution (synchronous)...\n",
      "Input message: Qual local voce recomenda para eu viajar?\n",
      "------------------------------------------------------------\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:08\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93minput_guard_rail.py:44\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🛡️ InputGuardRail: Starting execution\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:08\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93minput_guard_rail.py:59\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 📨 Processing message: Qual local voce recomenda para eu viajar?...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m[\u001b[90m2025-09-23 17:07:09\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:102\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 386, 'output_tokens': 57, 'total_tokens': 443, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 40}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:09\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93minput_guard_rail.py:71\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | ✅ Validation result: is_valid=True\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:09\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93minput_guard_rail.py:77\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🚀 Routing to next_node: reasoning_node\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:09\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mreasoning_node.py:28\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧠 ReasoningNode: Starting execution\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:09\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mreasoning_node.py:48\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 📨 Processing message: Qual local voce recomenda para eu viajar?...\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:11\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 959, 'output_tokens': 119, 'total_tokens': 1078, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 107}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:11\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34m_chat_model.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧰 invoke_with_tools: tool_calls=['list_registered_agents']\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:11\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34magent_registry.py:27\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🗂️ list_registered_agents: 2 agentes\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:12\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 1043, 'output_tokens': 167, 'total_tokens': 1210, 'input_token_details': {'cache_read': 726}, 'output_token_details': {'reasoning': 104}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:12\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34m_chat_model.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧰 invoke_with_tools: tool_calls=['invoke_agent']\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:12\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34magent_registry.py:36\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔁 invoke_agent: agent='AgenteDiagnosticoCarro', query[:120]='Qual o status do meu carro, nível de combustível e autonomia?'\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:12\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34magent_registry.py:98\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧩 AgentRegistry.invoke: agent='AgenteDiagnosticoCarro', query[:120]='Qual o status do meu carro, nível de combustível e autonomia?'\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:14\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 342, 'output_tokens': 67, 'total_tokens': 409, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 55}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:14\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34m_chat_model.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧰 invoke_with_tools: tool_calls=['get_car_status']\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:14\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;91mcar.py:24\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔧 Getting car status: gas_liters=36, current_autonomy=8\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:15\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 391, 'output_tokens': 106, 'total_tokens': 497, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 84}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:15\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34magent_registry.py:127\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧩 AgentRegistry.invoke: resposta len=75\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:15\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34magent_registry.py:41\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔁 invoke_agent: resposta len=75\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:16\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 1119, 'output_tokens': 58, 'total_tokens': 1177, 'input_token_details': {'cache_read': 734}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:16\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34m_chat_model.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧰 invoke_with_tools: tool_calls=['invoke_agent']\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:16\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34magent_registry.py:36\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔁 invoke_agent: agent='AgentePlanejadorViagem', query[:120]='Quais locais você recomenda para eu viajar, considerando que meu carro tem 36 litros de combustível e uma autonomia de 8'\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:16\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34magent_registry.py:98\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧩 AgentRegistry.invoke: agent='AgentePlanejadorViagem', query[:120]='Quais locais você recomenda para eu viajar, considerando que meu carro tem 36 litros de combustível e uma autonomia de 8'\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:18\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 798, 'output_tokens': 211, 'total_tokens': 1009, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 193}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:18\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34m_chat_model.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧰 invoke_with_tools: tool_calls=['recommend_locations']\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:18\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93mtravel.py:33\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🌍 recommend_locations: query='destinos variados'\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:18\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93mtravel.py:106\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🌍 recommend_locations: retornando 3 destinos\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:20\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 1048, 'output_tokens': 262, 'total_tokens': 1310, 'input_token_details': {'cache_read': 727}, 'output_token_details': {'reasoning': 241}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:20\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34m_chat_model.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧰 invoke_with_tools: tool_calls=['get_predicted_weather']\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:20\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mweather.py:39\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🌤️ Getting weather for Campos do Jordão: nublado\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:21\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 1098, 'output_tokens': 19, 'total_tokens': 1117, 'input_token_details': {'cache_read': 731}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:21\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34m_chat_model.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧰 invoke_with_tools: tool_calls=['get_predicted_weather']\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:21\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mweather.py:39\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🌤️ Getting weather for Florianópolis: chuvoso\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:25\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 1145, 'output_tokens': 498, 'total_tokens': 1643, 'input_token_details': {'cache_read': 734}, 'output_token_details': {'reasoning': 315}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:25\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34magent_registry.py:127\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧩 AgentRegistry.invoke: resposta len=667\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:25\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34magent_registry.py:41\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔁 invoke_agent: resposta len=667\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:27\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 1380, 'output_tokens': 231, 'total_tokens': 1611, 'input_token_details': {'cache_read': 771}, 'output_token_details': {'reasoning': 200}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:27\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34m_chat_model.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧰 invoke_with_tools: tool_calls=['is_trip_possible']\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:27\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mcalculations.py:20\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔧 Checking if trip is possible: distance=180.0, autonomy=8.0, gas=36.0\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:27\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mcalculations.py:27\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔧 Trip feasibility: needed_gas=22.5000, available_gas=36.0000, possible=True\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:29\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 1428, 'output_tokens': 280, 'total_tokens': 1708, 'input_token_details': {'cache_read': 772}, 'output_token_details': {'reasoning': 218}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:29\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mreasoning_node.py:71\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🚀 Routing to next_node: output_guard_rail\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:29\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93moutput_guard_rail.py:56\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🛡️ OutputGuardRail: Starting execution\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:29\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93moutput_guard_rail.py:68\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | ✅ Processing successful analysis\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:29\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93moutput_guard_rail.py:161\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔍 Validating recommendations for safety\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:41\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 832, 'output_tokens': 2016, 'total_tokens': 2848, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1736}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:41\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93moutput_guard_rail.py:204\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | ✅ Recommendations processed and validated\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:41\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93moutput_guard_rail.py:205\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 📤 Final message length: 1136 chars\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:41\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95m_algo.py:287\u001b[37m)\u001b[0m \u001b[33mWARNING\u001b[0m | Task output_guard_rail with path ('__pregel_pull', 'output_guard_rail') wrote to unknown channel branch:to:end, ignoring it.\n",
      "------------------------------------------------------------\n",
      "✅ Synchronous graph execution successful!\n",
      "\n",
      "📊 Final State:\n",
      "------------------------------\n",
      "Pergunta original:  Qual local voce recomenda para eu viajar?\n",
      "Resposta:  Com base na autonomia do seu carro (36 litros de combustível e 8 km/litro de autonomia), Campos do Jordão é o destino recomendado. A distância é de 180 km, e a viagem é possível com o combustível disponível. A previsão do tempo indica que estará nublado.\n"
     ]
    }
   ],
   "source": [
    "human_query = \"Qual local voce recomenda para eu viajar?\"\n",
    "sync_result = test_graph(app, human_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6381c892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Testing graph execution (synchronous)...\n",
      "Input message: Quero viajar 300 km amanhã. Com o combustível que tenho dá para ir sem reabastecer?\n",
      "------------------------------------------------------------\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:41\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93minput_guard_rail.py:44\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🛡️ InputGuardRail: Starting execution\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:41\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93minput_guard_rail.py:59\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 📨 Processing message: Quero viajar 300 km amanhã. Com o combustível que tenho dá para ir sem reabastecer?...\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:43\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:102\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 404, 'output_tokens': 102, 'total_tokens': 506, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 85}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:43\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93minput_guard_rail.py:71\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | ✅ Validation result: is_valid=True\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:43\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93minput_guard_rail.py:77\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🚀 Routing to next_node: reasoning_node\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:43\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mreasoning_node.py:28\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧠 ReasoningNode: Starting execution\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:43\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mreasoning_node.py:48\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 📨 Processing message: Quero viajar 300 km amanhã. Com o combustível que tenho dá para ir sem reabastecer?...\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:44\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 977, 'output_tokens': 91, 'total_tokens': 1068, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 79}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:44\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34m_chat_model.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧰 invoke_with_tools: tool_calls=['list_registered_agents']\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:44\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34magent_registry.py:27\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🗂️ list_registered_agents: 2 agentes\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:45\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 1061, 'output_tokens': 38, 'total_tokens': 1099, 'input_token_details': {'cache_read': 729}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:45\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34m_chat_model.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧰 invoke_with_tools: tool_calls=['invoke_agent']\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:45\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34magent_registry.py:36\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔁 invoke_agent: agent='AgenteDiagnosticoCarro', query[:120]='Qual o status do combustível e autonomia do meu carro?'\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:45\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34magent_registry.py:98\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧩 AgentRegistry.invoke: agent='AgenteDiagnosticoCarro', query[:120]='Qual o status do combustível e autonomia do meu carro?'\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:46\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 340, 'output_tokens': 64, 'total_tokens': 404, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 52}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:46\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34m_chat_model.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧰 invoke_with_tools: tool_calls=['get_car_status']\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:46\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;91mcar.py:24\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔧 Getting car status: gas_liters=36, current_autonomy=7\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:48\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 389, 'output_tokens': 237, 'total_tokens': 626, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 201}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:48\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34magent_registry.py:127\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧩 AgentRegistry.invoke: resposta len=142\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:48\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34magent_registry.py:41\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔁 invoke_agent: resposta len=142\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:50\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 1149, 'output_tokens': 139, 'total_tokens': 1288, 'input_token_details': {'cache_read': 740}, 'output_token_details': {'reasoning': 77}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:50\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34m_chat_model.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🧰 invoke_with_tools: tool_calls=['is_trip_possible']\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:50\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mcalculations.py:20\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔧 Checking if trip is possible: distance=300.0, autonomy=7.0, gas=36.0\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:50\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mcalculations.py:27\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔧 Trip feasibility: needed_gas=42.8571, available_gas=36.0000, possible=False\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:50\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 1197, 'output_tokens': 34, 'total_tokens': 1231, 'input_token_details': {'cache_read': 743}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:50\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;34mreasoning_node.py:71\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🚀 Routing to next_node: output_guard_rail\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:50\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93moutput_guard_rail.py:56\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🛡️ OutputGuardRail: Starting execution\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:50\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93moutput_guard_rail.py:68\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | ✅ Processing successful analysis\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:50\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93moutput_guard_rail.py:161\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🔍 Validating recommendations for safety\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:55\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:111\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 🪙 Token usage: {'input_tokens': 776, 'output_tokens': 537, 'total_tokens': 1313, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 421}}\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:55\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93moutput_guard_rail.py:204\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | ✅ Recommendations processed and validated\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:55\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93moutput_guard_rail.py:205\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | 📤 Final message length: 431 chars\n",
      "\u001b[37m[\u001b[90m2025-09-23 17:07:55\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95m_algo.py:287\u001b[37m)\u001b[0m \u001b[33mWARNING\u001b[0m | Task output_guard_rail with path ('__pregel_pull', 'output_guard_rail') wrote to unknown channel branch:to:end, ignoring it.\n",
      "------------------------------------------------------------\n",
      "✅ Synchronous graph execution successful!\n",
      "\n",
      "📊 Final State:\n",
      "------------------------------\n",
      "Pergunta original:  Quero viajar 300 km amanhã. Com o combustível que tenho dá para ir sem reabastecer?\n",
      "Resposta:  Com 36 litros de combustível e uma autonomia de 7 km/litro, você não conseguirá viajar 300 km sem reabastecer.\n"
     ]
    }
   ],
   "source": [
    "human_query = \"Quero viajar 300 km amanhã. Com o combustível que tenho dá para ir sem reabastecer?\"\n",
    "sync_result = test_graph(app, human_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
