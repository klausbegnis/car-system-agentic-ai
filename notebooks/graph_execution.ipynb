{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2aa3c1a",
   "metadata": {},
   "source": [
    "# Car System Agentic AI - Template\n",
    "\n",
    "**Project:** Agentic AI example  \n",
    "**Author:** Klaus  \n",
    "**License:** MIT License\n",
    "\n",
    "---\n",
    "\n",
    "This notebook demonstrates the car diagnostic system using LangGraph with multiple specialized nodes for input validation, reasoning, and output processing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfdbcfd",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfcfd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open(\"setup.py\").read())\n",
    "\n",
    "from notebooks import *\n",
    "from langgraph.constants import START\n",
    "from langgraph.graph import StateGraph\n",
    "from src.data_models.graph_state import CarSystemState\n",
    "from src.tools.car import get_car_status\n",
    "from src.tools.calculations import is_trip_possible\n",
    "from src.tools.travel import recommend_locations\n",
    "from src.tools.weather import get_predicted_weather\n",
    "from src.tools.agent_registry import list_registered_agents, invoke_agent\n",
    "from src.utils.prompt_loader import get_prompt\n",
    "from src.utils.agent_card_loader import load_agent_cards_from_file\n",
    "from src.services.agent_registry import AgentRegistry\n",
    "from src.utils.test_graph import test_graph\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c6571c",
   "metadata": {},
   "source": [
    "# Load Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77d6517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all prompts\n",
    "output_guard_rail_prompt = get_prompt(\"output_guard_rail\")\n",
    "input_guard_rail_prompt = get_prompt(\"input_guard_rail\")\n",
    "reasoning_node_prompt = get_prompt(\"reasoning_node\")\n",
    "car_central_prompt = get_prompt(\"car_central\")\n",
    "trip_planner_prompt = get_prompt(\"trip_planner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe5735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and register AgentCards from JSON (pt-BR)\n",
    "cards_path = Path.cwd().parent / \"data\" / \"agent_cards.json\"\n",
    "agent_cards = load_agent_cards_from_file(cards_path)\n",
    "AgentRegistry.clear()\n",
    "\n",
    "# Extract specific cards by name\n",
    "car_card = next(c for c in agent_cards if c.name == \"AgenteDiagnosticoCarro\")\n",
    "trip_card = next(c for c in agent_cards if c.name == \"AgentePlanejadorViagem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5940d3a4",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d4d94d",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d489588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specialized agents\n",
    "\n",
    "car_agent_model = models.GeminiModel(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    prompt=car_central_prompt,\n",
    "    agent_card=car_card,\n",
    "    tools=[get_car_status],\n",
    ")\n",
    "\n",
    "trip_planner_agent_model = models.GeminiModel(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    prompt=trip_planner_prompt,\n",
    "    agent_card=trip_card,\n",
    "    tools=[recommend_locations, get_predicted_weather],\n",
    ")\n",
    "\n",
    "# Register cards with their models\n",
    "AgentRegistry.register(car_card, car_agent_model)\n",
    "AgentRegistry.register(trip_card, trip_planner_agent_model)\n",
    "\n",
    "# Graph agents\n",
    "\n",
    "# Input guard rail agent\n",
    "input_guard_rail_agent = models.GeminiModel(\n",
    "    model=\"gemini-2.5-flash\", prompt=input_guard_rail_prompt\n",
    ")\n",
    "\n",
    "# Reasoning agent (orchestration + quick feasibility)\n",
    "reasoning_agent = models.GeminiModel(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    prompt=reasoning_node_prompt,\n",
    "    tools=[list_registered_agents, invoke_agent, is_trip_possible],\n",
    ")\n",
    "\n",
    "# Output guard rail agent\n",
    "output_guard_rail_agent = models.GeminiModel(\n",
    "    model=\"gemini-2.5-flash\", prompt=output_guard_rail_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e64c756",
   "metadata": {},
   "source": [
    "## Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e301d75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node definition\n",
    "ENTRYPOINT = START\n",
    "INPUT_GUARD_RAIL = \"input_guard_rail\"\n",
    "REASONING_NODE = \"reasoning_node\"\n",
    "OUTPUT_GUARD_RAIL = \"output_guard_rail\"\n",
    "EXIT_ZONE = \"end\"\n",
    "\n",
    "input_guard_rail = nodes.InputGuardRail(\n",
    "    routing_options={\"next_node\": REASONING_NODE, \"end\": OUTPUT_GUARD_RAIL},\n",
    "    model=input_guard_rail_agent,\n",
    ")\n",
    "\n",
    "reasoning_node = nodes.ReasoningNode(\n",
    "    routing_options={\"next_node\": OUTPUT_GUARD_RAIL, \"end\": OUTPUT_GUARD_RAIL},\n",
    "    model=reasoning_agent,\n",
    ")\n",
    "\n",
    "output_guard_rail = nodes.OutputGuardRail(\n",
    "    routing_options={\"end\": EXIT_ZONE},\n",
    "    model=output_guard_rail_agent,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12174ec2",
   "metadata": {},
   "source": [
    "## Graph Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213ceb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph with state_schema parameter\n",
    "workflow = StateGraph(state_schema=CarSystemState)\n",
    "\n",
    "# Add nodes to the graph\n",
    "workflow.add_node(INPUT_GUARD_RAIL, input_guard_rail)\n",
    "workflow.add_node(REASONING_NODE, reasoning_node)\n",
    "workflow.add_node(OUTPUT_GUARD_RAIL, output_guard_rail)\n",
    "\n",
    "# Define the flow with conditional routing\n",
    "# Os nodes usam Command para determinar o próximo node baseado no estado\n",
    "workflow.add_edge(START, \"input_guard_rail\")\n",
    "# workflow.add_edge(EXIT_ZONE, lambda state: Command(goto=END))\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513fd2ac",
   "metadata": {},
   "source": [
    "# Test Graph Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326c616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_query = \"Qual local voce recomenda para eu viajar?\"\n",
    "sync_result = test_graph(app, human_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6381c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_query = \"Quero viajar 300 km amanhã. Com o combustível que tenho dá para ir sem reabastecer?\"\n",
    "sync_result = test_graph(app, human_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
