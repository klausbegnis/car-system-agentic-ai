{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2aa3c1a",
   "metadata": {},
   "source": [
    "# Car System Agentic AI - Template\n",
    "\n",
    "**Project:** Agentic AI example  \n",
    "**Author:** Klaus  \n",
    "**License:** MIT License\n",
    "\n",
    "---\n",
    "\n",
    "This notebook demonstrates the car diagnostic system using LangGraph with multiple specialized nodes for input validation, reasoning, and output processing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfdbcfd",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cfcfd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m[\u001b[90m2025-09-19 17:33:50\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95m__init__.py:46\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | üîë Environment loaded from: /home/klaus/Projects/car-system-agentic-ai/.env\n",
      "\u001b[37m[\u001b[90m2025-09-19 17:33:50\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95m__init__.py:48\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | üîë GOOGLE_API_KEY: ‚úÖ Found\n"
     ]
    }
   ],
   "source": [
    "exec(open('setup.py').read())\n",
    "\n",
    "from notebooks import *\n",
    "from langgraph.constants import START, END\n",
    "from langgraph.graph import StateGraph\n",
    "from langchain_core.messages import HumanMessage\n",
    "from src.data_models.graph_state import CarSystemState\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.types import Command\n",
    "from src.tools.car import get_car_status\n",
    "from src.tools.calculations import is_trip_possible\n",
    "from src.utils.prompt_loader import get_prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c6571c",
   "metadata": {},
   "source": [
    "# Load Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f77d6517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m[\u001b[90m2025-09-19 17:33:50\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93mprompt_loader.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | üîç PromptLoader: Loaded prompt output_guard_rail\n",
      "\u001b[37m[\u001b[90m2025-09-19 17:33:50\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93mprompt_loader.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | üîç PromptLoader: Loaded prompt input_guard_rail\n",
      "\u001b[37m[\u001b[90m2025-09-19 17:33:50\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93mprompt_loader.py:129\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | üîç PromptLoader: Loaded prompt reasoning_node\n"
     ]
    }
   ],
   "source": [
    "# Load all prompts\n",
    "output_guard_rail_prompt = get_prompt(\"output_guard_rail\")\n",
    "input_guard_rail_prompt = get_prompt(\"input_guard_rail\") \n",
    "reasoning_node_prompt = get_prompt(\"reasoning_node\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5940d3a4",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d4d94d",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d489588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m[\u001b[90m2025-09-19 17:33:50\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:38\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | ü§ñ GeminiModel: Initialized with model gemini-2.5-flash\n",
      "\u001b[37m[\u001b[90m2025-09-19 17:33:50\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:38\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | ü§ñ GeminiModel: Initialized with model gemini-2.5-flash\n",
      "\u001b[37m[\u001b[90m2025-09-19 17:33:50\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:38\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | ü§ñ GeminiModel: Initialized with model gemini-2.5-flash\n"
     ]
    }
   ],
   "source": [
    "# model definition with prompts from markdown files\n",
    "input_guard_rail_agent = models.GeminiModel(\n",
    "    model=\"gemini-2.5-flash\", \n",
    "    prompt=input_guard_rail_prompt\n",
    ")\n",
    "\n",
    "reasoning_agent = models.GeminiModel(\n",
    "    model=\"gemini-2.5-flash\", \n",
    "    prompt=reasoning_node_prompt\n",
    ")\n",
    "\n",
    "output_guard_rail_agent = models.GeminiModel(\n",
    "    model=\"gemini-2.5-flash\", \n",
    "    prompt=output_guard_rail_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e64c756",
   "metadata": {},
   "source": [
    "## Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e301d75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m[\u001b[90m2025-09-19 17:33:50\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93minput_guard_rail.py:36\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | InputGuardRail: Initialized\n",
      "\u001b[37m[\u001b[90m2025-09-19 17:33:50\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95mnode_with_tools.py:55\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | NodeWithTools: Initialized\n",
      "\u001b[37m[\u001b[90m2025-09-19 17:33:50\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95moutput_guard_rail.py:41\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | OutputGuardRail: Initialized\n"
     ]
    }
   ],
   "source": [
    "# node definition\n",
    "ENTRYPOINT = START\n",
    "INPUT_GUARD_RAIL = \"input_guard_rail\"\n",
    "REASONING_NODE = \"reasoning_node\"\n",
    "OUTPUT_GUARD_RAIL = \"output_guard_rail\"\n",
    "EXIT_ZONE = \"end\"\n",
    "\n",
    "input_guard_rail = nodes.InputGuardRail(\n",
    "    routing_options={\"next_node\": REASONING_NODE, \"end\": OUTPUT_GUARD_RAIL},\n",
    "    model=input_guard_rail_agent,\n",
    ")\n",
    "\n",
    "reasoning_node = nodes.NodeWithTools(\n",
    "    routing_options={\"next_node\": OUTPUT_GUARD_RAIL, \"end\": OUTPUT_GUARD_RAIL},\n",
    "    model=reasoning_agent,\n",
    "    tools=[get_car_status, is_trip_possible],\n",
    ")\n",
    "\n",
    "output_guard_rail = nodes.OutputGuardRail(\n",
    "    routing_options={\"end\": EXIT_ZONE},\n",
    "    model=output_guard_rail_agent,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12174ec2",
   "metadata": {},
   "source": [
    "## Graph Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "213ceb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph with state_schema parameter\n",
    "workflow = StateGraph(state_schema=CarSystemState)\n",
    "\n",
    "# Add nodes to the graph\n",
    "workflow.add_node(INPUT_GUARD_RAIL, input_guard_rail)\n",
    "workflow.add_node(REASONING_NODE, reasoning_node)\n",
    "workflow.add_node(OUTPUT_GUARD_RAIL, output_guard_rail)\n",
    "\n",
    "# Define the flow with conditional routing\n",
    "# Os nodes usam Command para determinar o pr√≥ximo node baseado no estado\n",
    "workflow.add_edge(START, \"input_guard_rail\")\n",
    "#workflow.add_edge(EXIT_ZONE, lambda state: Command(goto=END))\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513fd2ac",
   "metadata": {},
   "source": [
    "# Test Graph Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b6aa706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üîÑ Running synchronous version...\n",
      "üîß Testing graph execution (synchronous)...\n",
      "Input message: Quero viajar 300 km amanh√£. Com o combust√≠vel que tenho d√° para ir sem reabastecer?\n",
      "------------------------------------------------------------\n",
      "\u001b[37m[\u001b[90m2025-09-19 17:33:50\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93minput_guard_rail.py:44\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | üõ°Ô∏è InputGuardRail: Starting execution\n",
      "\u001b[37m[\u001b[90m2025-09-19 17:33:50\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93minput_guard_rail.py:59\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | üì® Processing message: Quero viajar 300 km amanh√£. Com o combust√≠vel que tenho d√° para ir sem reabastecer?...\n",
      "\u001b[37m[\u001b[90m2025-09-19 17:33:52\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:74\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | ü™ô Token usage: {'input_tokens': 385, 'output_tokens': 112, 'total_tokens': 497, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 95}}\n",
      "\u001b[37m[\u001b[90m2025-09-19 17:33:52\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93minput_guard_rail.py:71\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | ‚úÖ Validation result: is_valid=True\n",
      "\u001b[37m[\u001b[90m2025-09-19 17:33:52\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93minput_guard_rail.py:77\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | üöÄ Routing to next_node: reasoning_node\n",
      "\u001b[37m[\u001b[90m2025-09-19 17:33:52\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95mnode_with_tools.py:118\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | üß† NodeWithTools: Starting execution\n",
      "\u001b[37m[\u001b[90m2025-09-19 17:33:52\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95mnode_with_tools.py:144\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | üì® Processing message: Quero viajar 300 km amanh√£. Com o combust√≠vel que tenho d√° para ir sem reabastecer?...\n",
      "\u001b[37m[\u001b[90m2025-09-19 17:33:55\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;93mcar.py:24\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | üîß Getting car status: gas_liters=43, current_autonomy=7\n",
      "\u001b[37m[\u001b[90m2025-09-19 17:33:56\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95mcalculations.py:20\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | üîß Checking if trip is possible: distance=300.0, autonomy=7.0, gas=43.0\n",
      "\u001b[37m[\u001b[90m2025-09-19 17:34:12\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95mnode_with_tools.py:169\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | üöÄ Routing to next_node: output_guard_rail\n",
      "\u001b[37m[\u001b[90m2025-09-19 17:34:12\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95moutput_guard_rail.py:56\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | üõ°Ô∏è OutputGuardRail: Starting execution\n",
      "\u001b[37m[\u001b[90m2025-09-19 17:34:12\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95moutput_guard_rail.py:68\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | ‚úÖ Processing successful analysis\n",
      "\u001b[37m[\u001b[90m2025-09-19 17:34:12\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95moutput_guard_rail.py:161\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | üîç Validating recommendations for safety\n",
      "\u001b[37m[\u001b[90m2025-09-19 17:34:25\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;94mgemini.py:83\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | ü™ô Token usage: {'input_tokens': 866, 'output_tokens': 2130, 'total_tokens': 2996, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1829}}\n",
      "\u001b[37m[\u001b[90m2025-09-19 17:34:25\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95moutput_guard_rail.py:204\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | ‚úÖ Recommendations processed and validated\n",
      "\u001b[37m[\u001b[90m2025-09-19 17:34:25\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95moutput_guard_rail.py:205\u001b[37m)\u001b[0m \u001b[32mINFO\u001b[0m | üì§ Final message length: 1305 chars\n",
      "\u001b[37m[\u001b[90m2025-09-19 17:34:25\u001b[37m]\u001b[0m \u001b[37m(\u001b[1;95m_algo.py:287\u001b[37m)\u001b[0m \u001b[33mWARNING\u001b[0m | Task output_guard_rail with path ('__pregel_pull', 'output_guard_rail') wrote to unknown channel branch:to:end, ignoring it.\n",
      "------------------------------------------------------------\n",
      "‚úÖ Synchronous graph execution successful!\n",
      "\n",
      "üìä Final State:\n",
      "------------------------------\n",
      "üìù messages: 7 messages\n",
      "   [0] HumanMessage: Quero viajar 300 km amanh√£. Com o combust√≠vel que tenho d√° para ir sem reabastec...\n",
      "   [1] AIMessage: ...\n",
      "   [2] ToolMessage: The car has 43 liters of gas and a current autonomy of 7 km/liters....\n",
      "   [3] AIMessage: ...\n",
      "   [4] ToolMessage: False...\n",
      "   [5] AIMessage: N√£o, n√£o √© poss√≠vel.\n",
      "\n",
      "Seu carro tem 43 litros de combust√≠vel e uma autonomia de ...\n",
      "   [6] AIMessage: Ol√°! Vamos analisar a situa√ß√£o do seu combust√≠vel para a viagem.\n",
      "\n",
      "Seu carro, com...\n",
      "üîπ processing_status: completed_successfully\n",
      "üîπ analysis_result: {'input': 'Quero viajar 300 km amanh√£. Com o combust√≠vel que tenho d√° para ir sem reabastecer?', 'analysis': 'N√£o, n√£o √© poss√≠vel.\\n\\nSeu carro tem 43 litros de combust√≠vel e uma autonomia de 7 km/litro, o que teoricamente permitiria percorrer 301 km. No entanto, para a viagem de 300 km, o sistema indica que n√£o √© suficiente.\\n\\nPara garantir a viagem, recomendo abastecer pelo menos 1 litro.', 'node': 'NodeWithTools'}\n",
      "üîπ recommendations: ['N√£o, n√£o √© poss√≠vel.\\n\\nSeu carro tem 43 litros de combust√≠vel e uma autonomia de 7 km/litro, o que teoricamente permitiria percorrer 301 km. No entanto, para a viagem de 300 km, o sistema indica que n√£o √© suficiente.\\n\\nPara garantir a viagem, recomendo abastecer pelo menos 1 litro.']\n",
      "\n",
      "üéâ Sync test completed! Final state has 4 populated fields.\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Alternative: Synchronous test (if async has issues)\n",
    "def test_graph_sync():\n",
    "    \"\"\"Synchronous version of the graph test.\"\"\"\n",
    "    \n",
    "    # Create a test state using CarSystemState\n",
    "    test_input = CarSystemState(\n",
    "        messages=[HumanMessage(content=\"Quero viajar 300 km amanh√£. Com o combust√≠vel que tenho d√° para ir sem reabastecer?\")],\n",
    "        user_input=None,\n",
    "        car_data=None,\n",
    "        current_node=None,\n",
    "        processing_status=None,\n",
    "        analysis_result=None,\n",
    "        recommendations=None,\n",
    "        error_message=None,\n",
    "        context=None,\n",
    "    )\n",
    "\n",
    "    config = RunnableConfig(config={\"run_name\": \"car-system-agentic-ai\"})\n",
    "\n",
    "    \n",
    "    print(\"üîß Testing graph execution (synchronous)...\")\n",
    "    print(f\"Input message: {test_input['messages'][0].content}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Run the graph synchronously\n",
    "        result = app.invoke(input=test_input, config=config)\n",
    "        print(\"-\" * 60)\n",
    "        print(\"‚úÖ Synchronous graph execution successful!\")\n",
    "        print(\"\\nüìä Final State:\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Display the results\n",
    "        for key, value in result.items():\n",
    "            if value is not None:\n",
    "                if key == \"messages\":\n",
    "                    print(f\"üìù {key}: {len(value)} messages\")\n",
    "                    for i, msg in enumerate(value):\n",
    "                        print(f\"   [{i}] {type(msg).__name__}: {msg.content[:80]}...\")\n",
    "                elif isinstance(value, str) and len(value) > 80:\n",
    "                    print(f\"üìÑ {key}: {value[:80]}...\")\n",
    "                else:\n",
    "                    print(f\"üîπ {key}: {value}\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during synchronous execution: {e}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        import traceback\n",
    "        print(f\"Traceback: {traceback.format_exc()}\")\n",
    "        return None\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üîÑ Running synchronous version...\")\n",
    "sync_result = test_graph_sync()\n",
    "\n",
    "if sync_result:\n",
    "    print(f\"\\nüéâ Sync test completed! Final state has {len([k for k, v in sync_result.items() if v is not None])} populated fields.\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Sync test also failed. Check configuration.\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
